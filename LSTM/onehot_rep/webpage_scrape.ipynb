{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2 as urllib\n",
    "import requests\n",
    "import keyword\n",
    "from bs4 import BeautifulSoup\n",
    "import keyword\n",
    "import re \n",
    "import itertools\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def code_extraction(input_file, output_file):\n",
    "    \n",
    "    \"\"\" read webpages from input_file, extract python codes from corresponding webpage and saved \n",
    "    the refined codeword into output_file\n",
    "    \n",
    "    Args:\n",
    "       input_file: from which txt file to read webpage list\n",
    "       output_file: to which csv file to write codeword into \n",
    "    \"\"\"\n",
    "    with open(input_file, \"rb\") as reader:\n",
    "        output_list = []\n",
    "        for line in reader:\n",
    "            # read webpage and scrape python source codes from it\n",
    "            webpage = line.rstrip()\n",
    "            web_file = urllib.urlopen(webpage)\n",
    "            soup = BeautifulSoup(web_file, \"lxml\")\n",
    "\n",
    "            # all kinds of codeword to extract \n",
    "            builtin_func = dir(__builtins__)  # builtin functions\n",
    "            keyword_list = keyword.kwlist  # builtin keywords\n",
    "            arith_operator = ['+', '-', '*', '/', '%', '//', '**']\n",
    "            comp_operator = ['>', '<', '!=', '==', '>=', '<=']\n",
    "            logic_operator = ['or', 'and', 'not']\n",
    "            assign_operator = ['=', '+=', '-=', '*=', '/=', '%=', '//=', '**=']\n",
    "            bracket = ['{', '}', '[', ']', '(', ')'] \n",
    "            special_symbol = [':']\n",
    "\n",
    "            # symbols to be omitted \n",
    "            omit_list = ['', ' ', ',', '\\n', '\"', \">>>\", \"...\", \"#\", '.']\n",
    "\n",
    "            filt = list(itertools.chain(builtin_func, keyword_list, arith_operator, \n",
    "                        comp_operator, logic_operator, assign_operator, bracket, special_symbol))\n",
    "\n",
    "            # delimiters to split string into list \n",
    "            delimiters = [',',' ', '(', ')', '[', ']', '{', '}', ':', \"...\", '\\n', '\"', '.', '>>>']\n",
    "            regexPattern = \"(\" + '|'.join(map(re.escape, delimiters)) + \")\"  \n",
    "\n",
    "            code_set = soup.find_all(\"div\", class_=\"highlight-python\")\n",
    "            for code_block in code_set:\n",
    "                code_refine = []\n",
    "                code_txt = code_block.get_text().encode('utf8')\n",
    "                code_txt = code_txt.split('\\n')\n",
    "                for code_line in code_txt:\n",
    "                    # extract only source code and omit substrings after # \n",
    "                    code_line = code_line.split(\"#\",1)[0]\n",
    "                    # replace substring within \"\" with x\n",
    "                    code_line = re.sub(r'\\\"(.+?)\\\"', \"x\", code_line)\n",
    "                    if code_line.startswith(\">>>\") or code_line.startswith(\"...\"):\n",
    "                        code_list = re.split(regexPattern, code_line) \n",
    "            #             print code_list\n",
    "                        for symbol in code_list:     \n",
    "                            if symbol in filt: \n",
    "                                code_refine.append(symbol)\n",
    "                            elif symbol not in omit_list:\n",
    "                                code_refine.append('x')\n",
    "                #  if code_refine is not empty\n",
    "                if code_refine:\n",
    "#                     print code_refine\n",
    "                    output_list.append(code_refine)\n",
    "#     print output_list\n",
    "    with open(output_file,'wb') as f:\n",
    "        pickle.dump(output_list,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert2onehot(input_file):\n",
    "    \"\"\" read codeword examples and convert them to onehot representation,\n",
    "    save the converted ones into data_onehot as list with each element of a numpy matrix \n",
    "    \n",
    "    Args:\n",
    "        input_file: from where to read .pkl file\n",
    "    \n",
    "    Returns:\n",
    "        data_onehot: data with onehot representation \n",
    "        data_index: data with index representation \n",
    "    \"\"\"\n",
    "    \n",
    "    # load .pkl file \n",
    "    with open(input_file,\"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    # flatten multi-level list into single-level list    \n",
    "    data_list = [element for lst in data for element in lst]\n",
    "    # obtain one-hot representation of each codeword\n",
    "    s = pd.Series(data_list)\n",
    "    onehot = pd.get_dummies(s)\n",
    "    codebook = list(onehot.columns.values)\n",
    "    onehot = onehot.as_matrix()\n",
    "    # save index of each codeword in index(list)\n",
    "    index = [int(np.nonzero(row)[0][0]) for row in onehot] \n",
    "    num_codeword = onehot.shape[1]\n",
    "    data_onehot = []\n",
    "    data_index = []\n",
    "    cnt = 0 \n",
    "    for lst in data:\n",
    "        lst_onehot = np.empty((0,num_codeword), dtype=int)\n",
    "        lst_index = []\n",
    "        for element in lst:\n",
    "            lst_onehot = np.concatenate((lst_onehot, onehot[cnt,:][np.newaxis,:]), axis = 0)\n",
    "            lst_index.append(index[cnt])\n",
    "            cnt += 1\n",
    "        data_onehot.append(lst_onehot) \n",
    "        data_index.append(lst_index)\n",
    "    return data_onehot, data_index, codebook\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!=', '%', '(', ')', '*', '**', '+', '-', '/', '//', ':', '<', '=', '==', '>', '>=', 'True', '[', ']', '__doc__', '__name__', 'abs', 'break', 'class', 'continue', 'def', 'del', 'dict', 'dir', 'elif', 'else', 'enumerate', 'filter', 'float', 'for', 'format', 'from', 'if', 'import', 'in', 'int', 'is', 'lambda', 'len', 'list', 'map', 'not', 'or', 'pass', 'print', 'range', 'raw_input', 'reduce', 'return', 'reversed', 'round', 'set', 'sorted', 'str', 'sum', 'unicode', 'while', 'x', 'xrange', 'zip', '{', '}']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    code_extraction(\"webpage_list.txt\", \"output.pkl\")\n",
    "    data_onehot, data_index = convert2onehot(\"output.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
